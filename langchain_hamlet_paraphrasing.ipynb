{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6a7ab57-fdeb-4b5d-9a2b-c3b577666a56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\n",
      " FRANCISCO at his post. Enter to him BERNARDO\n",
      "\n",
      "Paraphrased:\n",
      "  Francisco is on duty. Bernardo approaches him.\n",
      "\n",
      "In this context, \"Francisco at his post\" means that Francisco is on guard or performing his duties, and \"Enter to him BERNARDO\" implies that Bernardo entered the scene and approached Francisco.\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Create prompt template for paraphrasing\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"Paraphrase the following text in natural modern English:\\n\\n{text}\\n\\nParaphrase:\"\n",
    ")\n",
    "\n",
    "# Use a model via Ollama \n",
    "llm = OllamaLLM(model=\"mistral\")  \n",
    "\n",
    "# Create LangChain pipeline (prompt → model)\n",
    "chain = prompt | llm\n",
    "\n",
    "# Example Hamlet line to paraphrase\n",
    "text = \"FRANCISCO at his post. Enter to him BERNARDO\"\n",
    "\n",
    "# Run the chain \n",
    "paraphrased = chain.invoke({\"text\": text})\n",
    "\n",
    "# Print result\n",
    "print(\"Original:\\n\", text)\n",
    "print(\"\\nParaphrased:\\n\", paraphrased)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca4dfc43-5946-43a2-92e7-a85335dc78af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Paraphrasing: 100%|████████████████████████████████████████████████████████████████| 153/153 [2:08:26<00:00, 50.37s/it]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from langchain_ollama import OllamaLLM\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Load Hamlet dataset\n",
    "df = pd.read_csv(\"hamlet.csv\")\n",
    "\n",
    "# Add a new column for paraphrased text \n",
    "if \"paraphrased\" not in df.columns:\n",
    "    df[\"paraphrased\"] = None\n",
    "\n",
    "# Initialize LangChain + Ollama\n",
    "llm = OllamaLLM(model=\"mistral\") \n",
    "prompt = PromptTemplate.from_template(\n",
    "     \"Rewrite the following line in modern English. Do not explain or annotate. Just provide the modern version:\\n\\n{text}\"\n",
    ")\n",
    "chain = prompt | llm\n",
    "\n",
    "# Choose batch size\n",
    "BATCH_SIZE = 10\n",
    "\n",
    "# Start where left off\n",
    "start_idx = df[df[\"paraphrased\"].isna()].index.min()\n",
    "\n",
    "# Process in batches\n",
    "for i in tqdm(range(start_idx, len(df), BATCH_SIZE), desc=\"Paraphrasing\"):\n",
    "    batch = df.iloc[i:i + BATCH_SIZE]\n",
    "\n",
    "    for idx, row in batch.iterrows():\n",
    "        if pd.notnull(df.at[idx, \"paraphrased\"]):\n",
    "            continue  # already processed\n",
    "\n",
    "        try:\n",
    "            text = row[\"dialogue\"]\n",
    "            response = chain.invoke({\"text\": text})\n",
    "            df.at[idx, \"paraphrased\"] = response\n",
    "        except Exception as e:\n",
    "            df.at[idx, \"paraphrased\"] = f\"[ERROR] {e}\"\n",
    "\n",
    "    # Save progress after every batch\n",
    "    df.to_csv(\"hamlet_paraphrased.csv\", index=False)\n",
    "\n",
    "    # Optional pause to give CPU/GPU a breather\n",
    "    time.sleep(0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777e1511-2623-43ed-9972-d49541c16334",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
